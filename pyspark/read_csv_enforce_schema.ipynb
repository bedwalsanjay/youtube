{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7456af7d",
   "metadata": {},
   "source": [
    "# create SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "29ee879b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName(\"spark_reads\").master(\"local[4]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9f752ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_input_path=r'C:\\Users\\Sanjay Bedwal\\Desktop\\practice\\spark\\files\\csv\\input\\order1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fc52aa03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------------+-----------------+---------------+\n",
      "|_c0     |_c1                  |_c2              |_c3            |\n",
      "+--------+---------------------+-----------------+---------------+\n",
      "|order_id|order_date           |order_customer_id|order_status   |\n",
      "|1       |2013-07-25 00:00:00.0|11599            |CLOSED         |\n",
      "|2       |2013-07-25 00:00:00.0|256              |PENDING_PAYMENT|\n",
      "|3       |2013-07-25 00:00:00.0|12111            |COMPLETE       |\n",
      "|4       |2013-07-25 00:00:00.0|8827             |CLOSED         |\n",
      "|5       |2013-07-25 00:00:00.0|11318            |COMPLETE       |\n",
      "+--------+---------------------+-----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv_df=spark.read.csv(csv_input_path)\n",
    "csv_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "94d36474",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------------+-----------------+---------------+\n",
      "|order_id|order_date           |order_customer_id|order_status   |\n",
      "+--------+---------------------+-----------------+---------------+\n",
      "|1       |2013-07-25 00:00:00.0|11599            |CLOSED         |\n",
      "|2       |2013-07-25 00:00:00.0|256              |PENDING_PAYMENT|\n",
      "|3       |2013-07-25 00:00:00.0|12111            |COMPLETE       |\n",
      "|4       |2013-07-25 00:00:00.0|8827             |CLOSED         |\n",
      "|5       |2013-07-25 00:00:00.0|11318            |COMPLETE       |\n",
      "+--------+---------------------+-----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv_df=spark.read.option('header',True).csv(csv_input_path)\n",
    "csv_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1e9135cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('order_id', StringType(), True), StructField('order_date', StringType(), True), StructField('order_customer_id', StringType(), True), StructField('order_status', StringType(), True)])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0f1008a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- order_date: string (nullable = true)\n",
      " |-- order_customer_id: string (nullable = true)\n",
      " |-- order_status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "013455ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+\n",
      "|order_id|order_date         |order_customer_id|order_status   |\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "|1       |2013-07-25 00:00:00|11599            |CLOSED         |\n",
      "|2       |2013-07-25 00:00:00|256              |PENDING_PAYMENT|\n",
      "|3       |2013-07-25 00:00:00|12111            |COMPLETE       |\n",
      "|4       |2013-07-25 00:00:00|8827             |CLOSED         |\n",
      "|5       |2013-07-25 00:00:00|11318            |COMPLETE       |\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# csv_df=spark.read.option('header',True).option('inferSchema',True).csv(csv_file_path)\n",
    "csv_df=spark.read.options(header=True,inferSchema='True').csv(csv_input_path)\n",
    "csv_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9e5e9c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- order_date: timestamp (nullable = true)\n",
      " |-- order_customer_id: integer (nullable = true)\n",
      " |-- order_status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f92713",
   "metadata": {},
   "source": [
    "# enforcing the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6dad77fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType,StructField,IntegerType,StringType,TimestampType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f1f3e065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.student'>\n"
     ]
    }
   ],
   "source": [
    "class student:\n",
    "    pass\n",
    "\n",
    "s1=student()\n",
    "\n",
    "print(type(s1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3b2d3ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['order_id', 'order_date', 'order_customer_id', 'order_status']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create table stud \n",
    "# (\n",
    "#     id int,\n",
    "#     name char(10)\n",
    "    \n",
    "# )\n",
    "\n",
    "# write code here ----------------------\n",
    "\n",
    "# schema=StructType(\n",
    "#     [\n",
    "#        StructField(\"order_id\",IntegerType()), \n",
    "#        StructField(\"order_date\",TimestampType()),\n",
    "#        StructField(\"order_customer_id\",IntegerType()),\n",
    "#        StructField(\"order_status\",StringType()),\n",
    "        \n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# schema\n",
    "\n",
    "\n",
    "\n",
    "schema=StructType(\n",
    "[\n",
    "    StructField('order_id',IntegerType(),False,{\"description\" : 'This is a id of an order'}),\n",
    "    StructField('order_date',TimestampType()),\n",
    "    StructField('order_customer_id',IntegerType()),\n",
    "    StructField('order_status',StringType())\n",
    "]\n",
    ")\n",
    "\n",
    "schema.names\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "94625f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- order_date: timestamp (nullable = true)\n",
      " |-- order_customer_id: integer (nullable = true)\n",
      " |-- order_status: string (nullable = true)\n",
      "\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "|order_id|         order_date|order_customer_id|   order_status|\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|\n",
      "|       3|2013-07-25 00:00:00|            12111|       COMPLETE|\n",
      "|       4|2013-07-25 00:00:00|             8827|         CLOSED|\n",
      "|       5|2013-07-25 00:00:00|            11318|       COMPLETE|\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv_schema=StructType(\n",
    "[\n",
    "   StructField( 'order_id', IntegerType()) ,\n",
    "   StructField( 'order_date', TimestampType()) ,\n",
    "   StructField( 'order_customer_id', IntegerType()) ,  \n",
    "   StructField( 'order_status', StringType()) ,   \n",
    "]\n",
    ")\n",
    "\n",
    "# convert avro schema to spark schema \n",
    "# schema evoution , version maintain , \n",
    "\n",
    "csv_df=spark.read.options(header=True).schema(csv_schema).csv(csv_input_path)\n",
    "csv_df.printSchema()\n",
    "csv_df.show()\n",
    "# csv_df.schema['order_id']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3240288a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+-------------+------+\n",
      "|   name|age|         city|salary|\n",
      "+-------+---+-------------+------+\n",
      "|  Alice| 30|     New York| 50000|\n",
      "|    Bob| 25|San Francisco| 60000|\n",
      "|Charlie| 35|  Los Angeles| 75000|\n",
      "+-------+---+-------------+------+\n",
      "\n",
      "Metadata for the 'salary' column:\n",
      "{'description': 'Employee salary in USD'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "\n",
    "# Define a schema with metadata\n",
    "schema = StructType([\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"age\", IntegerType(), True),\n",
    "    StructField(\"city\", StringType(), True),\n",
    "    StructField(\"salary\", IntegerType(), True, {\"description\": \"Employee salary in USD\"})\n",
    "])\n",
    "\n",
    "# Create a DataFrame with the defined schema\n",
    "data = [(\"Alice\", 30, \"New York\", 50000),\n",
    "        (\"Bob\", 25, \"San Francisco\", 60000),\n",
    "        (\"Charlie\", 35, \"Los Angeles\", 75000)]\n",
    "\n",
    "df = spark.createDataFrame(data, schema=schema)\n",
    "\n",
    "# Show the DataFrame\n",
    "df.show()\n",
    "\n",
    "# Print the metadata for the \"salary\" column\n",
    "print(\"Metadata for the 'salary' column:\")\n",
    "print(df.schema[\"salary\"].metadata)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
